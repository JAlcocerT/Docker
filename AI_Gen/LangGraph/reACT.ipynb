{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/whitew1994WW/LangGraphForBeginners/blob/main/tutorial_react.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e9034b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b32b3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849df1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1d6d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt #all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6edfea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv==1.0.1\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52945244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Get API keys and other environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc5b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7d99870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph = StateGraph(State)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "788e382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7e81f437b070>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str):\n",
    "    \"\"\"Call to get the current weather.\"\"\"\n",
    "    if location.lower() in [\"yorkshire\"]:\n",
    "        return \"It's cold and wet.\"\n",
    "    else:\n",
    "        return \"It's warm and sunny.\"\n",
    "    \n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "graph.add_node(\"tool_node\", tool_node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb9f24fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7e81f437b070>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def prompt_node(state: State) -> State:\n",
    "    new_message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [new_message]}\n",
    "\n",
    "graph.add_node(\"prompt_node\", prompt_node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2952bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7e81f437b070>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conditional_edge(state: State) -> Literal['tool_node', '__end__']:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "    else:\n",
    "        return \"__end__\"\n",
    "    \n",
    "graph.add_conditional_edges(\n",
    "    'prompt_node',\n",
    "    conditional_edge\n",
    ")\n",
    "graph.add_edge(\"tool_node\", \"prompt_node\")\n",
    "graph.set_entry_point(\"prompt_node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Yorkshire is currently cold and wet.\n"
     ]
    }
   ],
   "source": [
    "APP = graph.compile()\n",
    "\n",
    "new_state = APP.invoke({\"messages\": [\"Whats the weather in yorkshire?\"]})\n",
    "\n",
    "print(new_state[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
