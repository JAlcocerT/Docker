# docker-compose -f docker-compose_caddy.yml down -v && docker-compose -f docker-compose_caddy.yml up -d

version: '3.8'

services:
  streamlit-multichat:
    image: ghcr.io/jalcocert/phidata:yt-groq #phidata:yt_summary_groq
    #image: ghcr.io/jalcocert/streamlit-multichat:v1.3
    container_name: streamlit_multichat
    #volumes:
    #  - ./app:/app
    #  - streamlit_config:/app/.streamlit
    #working_dir: /app
    #command: tail -f /dev/null
    command: streamlit run cookbook/llms/groq/video_summary/app.py
    # command: >
    #   sh -c "streamlit run Z_multichat.py --server.port=8501 --server.address=0.0.0.0 --server.enableCORS=false"
    expose:
      - "8501"
    restart: unless-stopped
    environment:
      - MODEL_API_KEY=${MODEL_API_KEY:-sk-proj-openaiAPIhere}
      - MODEL=${MODEL:-gpt-4o-mini}
      - TEMPERATURE=${TEMPERATURE:-0}
    networks:
      - caddy-net

  caddy:
    image: caddy:latest
    container_name: caddy
    ports:
      - "8443:8443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    restart: unless-stopped
    networks:
      - caddy-net
    environment:
      - ACME_AGREE=false

networks:
  caddy-net:
    driver: bridge

volumes:
  ai_streamlit_multichat:
  caddy_data:
  caddy_config:
  streamlit_config:
#     driver: bridge

# volumes:
#   ai_streamlit_multichat:

